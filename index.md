---
layout: page
title: Welcome!
toc: true
---

Welcome to my personal website! I'm Antonia, an MEng and BA (Hons) graduate from the University of Cambridge.
I was a member of King's College, and my [Director of Studies](https://www.dow.cam.ac.uk/undergraduate-study/study-downing/directors-studies) was the lovely [Prof Timothy G. Griffin](https://www.cl.cam.ac.uk/~tgg22/).

My research interests lie within the field of Machine Learning, with a focus on **graph neural networks** and their applications in molecular tasks. I wrote my Master's thesis under the supervision of [Prof Pietro Lio](https://www.cl.cam.ac.uk/~pl219/) and two of his wonderfully talented PhD students, [Simon V. Mathis](https://www.cst.cam.ac.uk/people/svm34) and [Charlie Harris](https://cch1999.github.io). 

## Research projects
### 2023
- [[Master's thesis]({% post_url 2023-09-18-thesis %})]. _Structure-informed protein engineering using equivariant graph neural entworks_. This work was accepted to the [ICML 2023 Workshop in Computational Biology](https://icml-compbio.github.io). 

- [[Degree coursework]({% post_url 2023-09-19-l45 %})]. _Efficient long-range interaction modelling in molecular graphs and proteins_. In this 8-week research project, we investigate whether adding random long-range edges to molecular graphs improves the performance of equivariant graph neural networks for molecular function prediction.

- [[Degree coursework]({% post_url 2023-09-19-r255 %})]. _Undesirable communication behaviour in cooperative agents with decentralised critics_. In this 4-week research project on [multi-agent reinforcement learning](https://en.wikipedia.org/wiki/Multi-agent_reinforcement_learning), I add communication channels to decentralised actors that work together to cover a map with obstacles. 

- [[Degree coursework]({% post_url 2023-09-19-r252 %})]. _Towards an even better understanding of sharpness-aware minimisation_. In this 6-week research project, my team and I investigate why the batched, stochastic version of [the SAM optimiser](https://arxiv.org/abs/2010.01412) is better at improving generalisation performance than the original SAM optimiser.

- [[Degree coursework]()]. _Pruned teachers are friendly teachers: improving knowledge distillation in GAT networks_. In this 6-week research project, I prune a teacher [GAT network](https://arxiv.org/abs/1710.10903) and then distill it, showing this improves the performance of the student model.

### 2022
- [[Degree coursework]()]. _An analysis of multi-GPU training performance in GNN libraries_. In this 6-week project, I compare the performances of [PyTorch Geometric](https://pytorch-geometric.readthedocs.io) and [Deep Graph Library](https://www.dgl.ai) in a distributed training environment, and find that both suffer from bottlenecks which prohibit them from taking full advantage of the underlying hardware.

- [[Bachelor's thesis]()]. _Evaluation of a semi-supervised expectation-based dependency parser_. In my Bachelor's thesis, I investigate whether a semi-supervised training technique can improve the performance of a [dependency parser](https://towardsdatascience.com/natural-language-processing-dependency-parsing-cf094bbbe3f7) when dealing with [low-resource languages](https://medium.com/neuralspace/low-resource-language-what-does-it-mean-d067ec85dea5). My work received the award for the **best undegraduate poster** at the [Oxbridge Women in Computer Science Conference](https://www.oxwocs.com/events/oxbridge-women-in-computer-science-Conference).

--- 

## Work experience

- _September 2023 - present_. I work full-time as a quantitative developer at [Quadrature Capital](https://quadrature.ai), in London, UK. 

- _July 2022 - September 2022_. I was a quantitative development intern at Quadrature Capital. My work was focused on the research side of the business, as I investigated financial signals coming from [Credit Default Swaps](https://www.investopedia.com/terms/c/creditdefaultswap.asp) and the way they can be incorporated into the internal ML trading systems. My project allowed me to interact with multiple teams working at different levels of the "research stack", therefore allowing me to build a holistic understanding of the alpha and risk prediction paltforms. 

- _July 2021 - September 2021_. I was a quantitative development intern at Quadrature Capital. During this internship, my work was focused on the systems side of the business, and I was tasked with improving market data-handling processes using C++, to which I brought a 10% speed-up.

- _July 2020 - September 2020_. I was a [STEP intern](https://buildyourfuture.withgoogle.com/programs/step) at Google. I worked remotely (this was during COVID-19) for a team of software engineers in Google Zurich. I developed an open-source project meant to automate the management of a local community of around 1500 members. Here is the [link](https://github.com/googleinterns/step236-2020) to the open-source code. 

---

## Random fun stuff I've worked on

- _Spring 2023_. I took the [Intro into ML Safety](https://course.mlsafety.org/about) course from the [Center for AI Safety](https://www.safe.ai). This was a 7-week course with readings and coursework on various AI Safety topics, such as Robustness, Monitoring, and AI alignment.

- _Autumn 2022_. I participated in the [Cambridge AI Safety Hub](https://www.cambridgeaisafety.org) fellowship. For 2 months, weekly discussions were held on all [introductory AI safety topics](https://www.cambridgeaisafety.org/intro). 

- _Spring 2022_. Check out [this essay]({{ site.url }}/assets/intro_to_dnns.pdf) that I wrote in collaboration with one of my biochemist friends on _what is a deep neural network?_ It won the **John Rose prize** at King's College, Cambridge for the **best explanation of a scientific principle of general interest**. 

